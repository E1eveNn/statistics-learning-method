{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3算法\n",
    "输入：训练数据集D，特征集A，阈值epsilon；\n",
    "输出：决策树T\n",
    "（1）若D中所有实例属于同一类Ck，则T为单结点树，并将类Ck作为该结点的类标记，返回T；\n",
    "\n",
    "（2）若A=∅，则T为单结点树，并将D中实例最大的类Ck作为该结点的类标记，返回T；\n",
    "\n",
    "（3）否则，计算A中各特征对D的信息增益，选择信息增益最大的特征Ag；\n",
    "\n",
    "（4）如果Ag的信息增益小于阈值epsilon，则置T为单结点树，并将D中实例数最大的类Ck作为该结点的类标记，返回T；\n",
    "\n",
    "（5）否则，对Ag的每一可能值ai，依Ag=ai将D分割为若干非空子集Di，将Di中实例数最大的类作为标记，构建子结点，由结点及其子结点构成树T，返回T；\n",
    "\n",
    "（6）对第i个子结点，以Di为训练集，以A-{Ag}为特征集，递归地调用步（1）~步（5），得到子树Ti，返回Ti；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ID3_tree_pics/formula1.png'></img>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ID3_tree_pics/formula2.png'></img>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ID3_tree_pics/formula3.png'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import math\n",
    "\n",
    "\n",
    "def create_data():\n",
    "    dataSets = [['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return dataSets, labels\n",
    "\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, label=None, featureIndex=None,feature_name=None, \n",
    "                 parentNode=None, leaf=False,entropy=0):\n",
    "        self.label = label\n",
    "        self.leaf = leaf  # 是否为叶结点\n",
    "        self.featureIndex = featureIndex\n",
    "        self.feature_name = feature_name\n",
    "        self.parentNode = parentNode\n",
    "        self.childNodeList = {}  # 存的是子结点的取值，如feature_name是身高，可能存的是高，矮\n",
    "        self.entropy=entropy\n",
    "        self.sampleLists=[]\n",
    "        self.prune_visited=False\n",
    "\n",
    "\n",
    "    def predict(self,node,Xtest):\n",
    "        if node.leaf:\n",
    "            return node.label\n",
    "        else:\n",
    "            currentFeatIndex=node.featureIndex\n",
    "            currentFeatVal=Xtest[currentFeatIndex]\n",
    "            return self.predict(node.childNodeList[currentFeatVal],Xtest)\n",
    "\n",
    "\n",
    "\n",
    "class dTree:\n",
    "    def __init__(self, epsilon=0.1,alpha=0.3):\n",
    "        self.epsilon = epsilon\n",
    "        self.myTree = None\n",
    "        self.completeDataSets=None\n",
    "        self.completeAttrs=None\n",
    "        self.leafNums=0\n",
    "        self.alpha=alpha  #用于剪枝\n",
    "\n",
    "\n",
    "    def treeGenerate(self,dataSets,labels):\n",
    "        self.myTree=Node(parentNode='root')\n",
    "        self.completeDataSets=dataSets.copy()\n",
    "        self.completeAttrs=labels.copy()\n",
    "        self.recursive(dataSets,labels,self.myTree)\n",
    "        print(\"generate tree success!\")\n",
    "\n",
    "\n",
    "    def recursive(self, dataSets, labels, node=Node()):\n",
    "        if self.isSameClass(dataSets):\n",
    "            node.label = dataSets[0][-1]\n",
    "            node.leaf = True\n",
    "            node.entropy=self.calcEntropy(dataSets)\n",
    "            node.sampleLists=dataSets\n",
    "            self.leafNums+=1\n",
    "            return\n",
    "        if len(labels[:-1]) == 0:\n",
    "            node.label = self.majorityClass(dataSets)\n",
    "            node.leaf = True\n",
    "            node.entropy = self.calcEntropy(dataSets)\n",
    "            node.sampleLists = dataSets\n",
    "            self.leafNums += 1\n",
    "            return\n",
    "\n",
    "        bestFeatIndex = self.chooseBestFeatureToSplit(dataSets, labels)\n",
    "        node.featureIndex = bestFeatIndex\n",
    "        node.feature_name = self.completeAttrs[bestFeatIndex]\n",
    "        node.entropy=self.calcEntropy(dataSets)\n",
    "        node.sampleLists=dataSets\n",
    "        featList = [data[bestFeatIndex] for data in self.completeDataSets]\n",
    "        uniqueFeatList = set(featList)\n",
    "        for feat in uniqueFeatList:\n",
    "            subNode = Node()\n",
    "            node.childNodeList[feat]=subNode\n",
    "            subNode.parentNode = node\n",
    "            subDataSets = self.splitData(dataSets, bestFeatIndex, feat)\n",
    "            if len(subDataSets) == 0:\n",
    "                subNode.label = self.majorityClass(dataSets)\n",
    "                subNode.leaf = True\n",
    "                self.leafNums += 1\n",
    "            else:\n",
    "                subLabels = labels.copy()\n",
    "                subLabels.remove(self.completeAttrs[bestFeatIndex])\n",
    "                self.recursive(subDataSets, subLabels, subNode)\n",
    "\n",
    "\n",
    "\n",
    "    def chooseBestFeatureToSplit(self, dataSets, labels):\n",
    "        baseEntropy = self.calcEntropy(dataSets)\n",
    "        m = len(dataSets)\n",
    "        bestInfoGain = -math.inf\n",
    "        bestFeatIndex = -1\n",
    "        for i in range(len(labels) - 1):  # 遍历每个属性\n",
    "            j=self.completeAttrs.index(labels[i])\n",
    "            featList = [data[j] for data in dataSets]\n",
    "            uniqueFeats = set(featList)  # 当前属性的取值\n",
    "            newEntropy = 0\n",
    "            for feat in uniqueFeats:  # 遍历当前属性的每个取值\n",
    "                subDataSets = self.splitData(dataSets, j, feat)\n",
    "                prob = len(subDataSets) / m\n",
    "                newEntropy += prob * self.calcEntropy(subDataSets)\n",
    "            currentInfoGain = baseEntropy - newEntropy\n",
    "            if currentInfoGain >= bestInfoGain:\n",
    "                bestInfoGain = currentInfoGain\n",
    "                bestFeatIndex = j\n",
    "        return bestFeatIndex\n",
    "\n",
    "\n",
    "    def splitData(self, dataSets, featIndex, featVals):\n",
    "        subDataSets = [data for data in dataSets if data[featIndex] == featVals]\n",
    "        return subDataSets\n",
    "\n",
    "\n",
    "    def calcEntropy(self, dataSets):\n",
    "        informationEnt = 0\n",
    "        m = len(dataSets)\n",
    "        classCountDict = self.classCount(dataSets)\n",
    "        for key in classCountDict.keys():\n",
    "            prob = classCountDict[key] / m\n",
    "            if prob == 0.0:\n",
    "                Ent = 0.0\n",
    "            else:\n",
    "                Ent = prob * math.log(prob,2)\n",
    "            informationEnt -= Ent\n",
    "        return informationEnt\n",
    "\n",
    "    def isSameClass(self, dataSets):\n",
    "        C = dataSets[0][-1]  # 第一个样本的类\n",
    "        for data in dataSets:\n",
    "            if C != data[-1]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "    def majorityClass(self, dataSets):\n",
    "        classCountDict = self.classCount(dataSets)\n",
    "        sortedClassCount = sorted(classCountDict.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        return sortedClassCount[0][0]\n",
    "\n",
    "\n",
    "    def classCount(self,dataSets):\n",
    "        classCountDict = {}\n",
    "        for data in dataSets:\n",
    "            if data[-1] not in classCountDict.keys():\n",
    "                classCountDict[data[-1]] = 1\n",
    "            else:\n",
    "                classCountDict[data[-1]] += 1\n",
    "        return classCountDict\n",
    "\n",
    "#后剪枝\n",
    "    def postPruning(self):\n",
    "        count=0\n",
    "        leafParentNode = self.getTheLeafParentNode(self.myTree)  #找到一个子结点全是叶结点的结点，并且该结点的prune_visited=False\n",
    "        while leafParentNode.parentNode!='root':  #找到根结点时停止\n",
    "            beforeLoss = self.compute_recursive(self.myTree)+self.alpha*self.leafNums\n",
    "            tmpLeafChildNode = leafParentNode.childNodeList.copy()  #将该结点的子结点保存起来\n",
    "            leafParentNode.childNodeList = {}  #先假设将子结点剪了\n",
    "            afterLoss = self.compute_recursive(self.myTree)+self.alpha*(self.leafNums-len(tmpLeafChildNode)+1)\n",
    "            if afterLoss > beforeLoss:  # 如果剪了后损失值更大了，就不剪\n",
    "                leafParentNode.childNodeList = tmpLeafChildNode\n",
    "            else:\n",
    "                leafParentNode.leaf=True\n",
    "                leafParentNode.label=self.majorityClass(leafParentNode.sampleLists)\n",
    "                self.leafNums=self.leafNums-len(tmpLeafChildNode)+1\n",
    "                print(\"prune node: %s\"%(leafParentNode.feature_name))\n",
    "                count+=1\n",
    "            leafParentNode = self.getTheLeafParentNode(self.myTree)  #寻找下一个子结点全是叶结点的结点\n",
    "        print(\"prune finished,cut %d node!\"%count)\n",
    "\n",
    "\n",
    "    def compute_recursive(self,tree):\n",
    "        loss=0\n",
    "        if tree.childNodeList:  #如果当前结点有子结点\n",
    "            for featVal,childNode in tree.childNodeList.items():\n",
    "                loss+=self.compute_recursive(childNode)\n",
    "        else:   #当前结点为叶结点\n",
    "            loss+=len(tree.sampleLists)*tree.entropy\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def getTheLeafParentNode(self,tree):\n",
    "        isAllChildNodeLeaf=True\n",
    "        if tree.childNodeList:  #如果当前结点有子结点，即不是叶结点\n",
    "            for key,childNode in tree.childNodeList.items():#遍历当前结点的所有子结点\n",
    "                if childNode.prune_visited:\n",
    "                    continue\n",
    "                if childNode.childNodeList:  #当前迭代下的子结点如果还有子结点，即不是叶节点的话\n",
    "                    isAllChildNodeLeaf=False\n",
    "                    return self.getTheLeafParentNode(childNode)  #递归地对非叶结点调用此方法\n",
    "            if isAllChildNodeLeaf and not tree.prune_visited:   #如果当前结点所有子结点都是叶结点\n",
    "                tree.prune_visited=True\n",
    "                return tree\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self,Xtest):\n",
    "        return self.myTree.predict(self.myTree,Xtest)\n",
    "\n",
    "\n",
    "    def score(self,testDatas):\n",
    "        #testDatas需要是至少有两个样本的list\n",
    "        y=[data[-1] for data in testDatas]\n",
    "        predictY=[]\n",
    "        for Xtest in testDatas:\n",
    "            predictY.append(self.predict(Xtest[:-1]))\n",
    "        m=len(y)\n",
    "        count=0\n",
    "        for i in range(m):\n",
    "            if y[i]==predictY[i]:\n",
    "                count+=1\n",
    "        accuracy=float(count/m)*100\n",
    "        print(y)\n",
    "        print(predictY)\n",
    "        print(\"accuracy is \"+str(accuracy)+\"%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate tree success!\n",
      "['否', '否', '是', '是', '否', '否', '否', '是', '是', '是', '是', '是', '是', '是', '否']\n",
      "['否', '否', '是', '是', '否', '否', '否', '是', '是', '是', '是', '是', '是', '是', '否']\n",
      "accuracy is 100.0%\n",
      "prune finished,cut 0 node!\n"
     ]
    }
   ],
   "source": [
    "firstDataSets,firstLabels=create_data()\n",
    "firstMyTree=dTree()\n",
    "firstMyTree.treeGenerate(firstDataSets,firstLabels)\n",
    "firstMyTree.score(firstDataSets)\n",
    "firstMyTree.postPruning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一组数据生成的决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./ID3_tree_pics/Figure_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate tree success!\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "accuracy is 100.0%\n",
      "prune finished,cut 0 node!\n"
     ]
    }
   ],
   "source": [
    "secondDataSets=[\n",
    "['青绿','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['乌黑','蜷缩','沉闷','清晰','凹陷','硬滑',1],\n",
    "['乌黑','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['青绿','蜷缩','沉闷','清晰','凹陷','硬滑',1],\n",
    "['浅白','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['青绿','稍蜷','浊响','清晰','稍凹','软粘',1],\n",
    "['乌黑','稍蜷','浊响','稍糊','稍凹','软粘',1],\n",
    "['乌黑','稍蜷','浊响','清晰','稍凹','硬滑',1],\n",
    "['乌黑','稍蜷','沉闷','稍糊','稍凹','硬滑',0],\n",
    "['青绿','硬挺','清脆','清晰','平坦','软粘',0],\n",
    "['浅白','硬挺','清脆','模糊','平坦','硬滑',0],\n",
    "['浅白','蜷缩','浊响','模糊','平坦','软粘',0],\n",
    "['青绿','稍蜷','浊响','稍糊','凹陷','硬滑',0],\n",
    "['浅白','稍蜷','沉闷','稍糊','凹陷','硬滑',0],\n",
    "['乌黑','稍蜷','浊响','清晰','稍凹','软粘',0],\n",
    "['浅白','蜷缩','浊响','模糊','平坦','硬滑',0],\n",
    "['青绿','蜷缩','沉闷','稍糊','稍凹','硬滑',0]]\n",
    "\n",
    "secondLabels=[u'色泽', u'根蒂', u'敲声', u'纹理', u'脐部', u'触感',u'类别']\n",
    "\n",
    "\n",
    "secondMyTree=dTree()\n",
    "secondMyTree.treeGenerate(secondDataSets,secondLabels)\n",
    "secondMyTree.score(secondDataSets)\n",
    "secondMyTree.postPruning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二组数据生成的决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./ID3_tree_pics/Figure_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate tree success!\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "accuracy is 100.0%\n",
      "prune finished,cut 0 node!\n"
     ]
    }
   ],
   "source": [
    "thirdDataSets=[\n",
    "['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 1],\n",
    "['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', 1],\n",
    "['乌黑', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 1],\n",
    "['青绿', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 1],\n",
    "['乌黑', '稍蜷', '浊响', '稍糊', '稍凹', '软粘', 1],\n",
    "['青绿', '硬挺', '清脆', '清晰', '平坦', '软粘', 0],\n",
    "['浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', 0],\n",
    "['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 0],\n",
    "['浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', 0],\n",
    "['青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑', 0]]\n",
    "\n",
    "thirdLabels=[u'色泽', u'根蒂', u'敲声', u'纹理', u'脐部', u'触感',u'类别']\n",
    "\n",
    "thirdTestDataSets=[\n",
    "['青绿','蜷缩','沉闷','清晰','凹陷','硬滑',1],\n",
    "['浅白','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['乌黑','稍蜷','浊响','清晰','稍凹','硬滑',1],\n",
    "['乌黑','稍蜷','沉闷','稍糊','稍凹','硬滑',0],\n",
    "['浅白','硬挺','清脆','模糊','平坦','硬滑',0],\n",
    "['浅白','蜷缩','浊响','模糊','平坦','软粘',0],\n",
    "['青绿','稍蜷','浊响','稍糊','凹陷','硬滑',0]]\n",
    "\n",
    "thirdMyTree=dTree()\n",
    "thirdMyTree.treeGenerate(thirdDataSets,thirdLabels)\n",
    "thirdMyTree.score(thirdDataSets)\n",
    "thirdMyTree.postPruning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三组数据生成的决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./ID3_tree_pics/Figure_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 0, 0]\n",
      "accuracy is 85.71428571428571%\n"
     ]
    }
   ],
   "source": [
    "thirdMyTree.score(thirdTestDataSets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为何以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的特征的问题：\n",
    "可以这样想假如这个特征取值特别多，每个样本就有一个取值，如果选择这个特征，那么每个分支都只有一条实例，也就是每个分支都属于同一个类，这个分支的熵就是0，这个特征的条件熵也就是0，那么基于这个特征的信息增益g(D,A)=H(D)-0=H(D)，就会是最大的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树的剪枝\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树的剪枝分为预剪枝和后剪枝，预剪枝则是判断划分当前结点后验证集精确度是否提高（西瓜书），或者是损失函数值是否减少（统计学习方法），若是，则划分。而后剪枝是先生成好决策树，递归地试试删除结点能否提高验证集精确度或者减少损失函数值，若是，则剪枝。本模型只实现了postpruning（后剪枝）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对于连续属性的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定样本集D和连续属性a，假定a在D上出现了n个不同的取值，将这些值从小到大进行排序，记为{a1,a2,...,an}，基于划分点t可将D分为子集Dt-,Dt+，Dt-包含a上取值不大于t的样本，而Dt+则包含那些在属性a上取值大于t的样本Gain(D,a)=max Gain(D,a,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet,contiualLabels):  #dataSet只包含连续属性\n",
    "    baseEntropy=self.calcEntropy(labels)\n",
    "    bestInfoGain=-math.inf\n",
    "    bestT=-1\n",
    "    for k in range(len(contiualLabels)):\n",
    "        featList = [float(example[k]) for example in dataSets]\n",
    "        sortedFeatList=featList.copy()\n",
    "        sortedFeatList.sort()\n",
    "        #求Ta\n",
    "        for j in range(len(featList)-1):\n",
    "            InfoGain = 0\n",
    "            T=0.5*(sortedFeatList[j]+sortedFeatList[j+1])\n",
    "            posDataSets,negDataSets=splitDataByT(dataSets,k,T)\n",
    "            InfoGain=InfoGain+((len(posDataSets)/len(dataSet))*calcEntropy(posDataSets))+((len(negDataSets)/len(dataSet))*calcEntropy(negDataSets))\n",
    "            Gain=baseEntropy-InfoGain\n",
    "            if Gain > bestInfoGain:\n",
    "                bestInfoGain = Gain\n",
    "                bestFeature = k\n",
    "                bestT=T\n",
    "    return bestFeature,bestT\n",
    "\n",
    "\n",
    "def splitDataByT(dataSets,featIndex,T):\n",
    "    posDataSets=[data for data in dataSets if data[featIndex]>T]\n",
    "    negDataSets=[data for data in dataSets if data[featIndex]<=T]\n",
    "    return posDataSets,negDataSets\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "连续属性的处理见上面代码\n",
    "需注意的是，与离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性。\n",
    "例如在父结点上使用了“密度<=0.381”不会禁止在子结点上使用“密度<=0.294”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
