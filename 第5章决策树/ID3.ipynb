{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3算法\n",
    "输入：训练数据集D，特征集A，阈值epsilon；\n",
    "输出：决策树T\n",
    "（1）若D中所有实例属于同一类Ck，则T为单结点树，并将类Ck作为该结点的类标记，返回T；\n",
    "\n",
    "（2）若A=∅，则T为单结点树，并将D中实例最大的类Ck作为该结点的类标记，返回T；\n",
    "\n",
    "（3）否则，计算A中各特征对D的信息增益，选择信息增益最大的特征Ag；\n",
    "\n",
    "（4）如果Ag的信息增益小于阈值epsilon，则置T为单结点树，并将D中实例数最大的类Ck作为该结点的类标记，返回T；\n",
    "\n",
    "（5）否则，对Ag的每一可能值ai，依Ag=ai将D分割为若干非空子集Di，将Di中实例数最大的类作为标记，构建子结点，由结点及其子结点构成树T，返回T；\n",
    "\n",
    "（6）对第i个子结点，以Di为训练集，以A-{Ag}为特征集，递归地调用步（1）~步（5），得到子树Ti，返回Ti；"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKcAAAASCAYAAAA+Ec4qAAAG0UlEQVRoBe2aBahtRRSGv2cn2N3dCHZ3J7ZioKDYYneiooLyFAMLxUZRFLsVuxu7UKyHgd3K91xzGcY55+5z3n33nqvvh3v37NlrYs+sWetfa58RDCxmBz5q2OXUwO/Adw3lh1JsFmCBLibwNPBjtFscuATYF1gfmAHYr4s+/zdNxhvAN90WmL+D/n4Ajgam6KDNUInOBNwLXAv0t2ZzAbsCdwN7ZBP+Jg7jbIBK+0v2rNeK8wAT99qknM9SwJXAQ8D1gCdeLJTVnw3MGPVeVgEOy+6bFqcELmsqPMRyRwJ/ASc1nIdKemumzLsBd0TbM4C1G/YzmGIaFw+h7znHYA7cyVgXAT8B0xWNzgR+A6Yp6u8BJi3qmt4eASzbVHgI5UYA9wF/ACs3nIcW18MutLrrRflZQKpgn72G1XtdOV+MU18u3JPAg0XlSsDlRV0nt27gLZ00GEJZD+so4FNgqg7n8SEwfrT5BFiww/aDJb58LyunRF2zvmexGm7Mn4CWLocuaqe8IisvAhwTVsJqX3yH7HkqPg9MkG56/LpWrMPtPT5Pp+eaLgFIKSYDdgT2z/aj9go15dTKnwycGnphXznk0QcE7Tsc0PqW3kUvIW3YHpgTcB2VlS5WUVOIDULSgMVBEtYMNyTRzyHfvCaviLJWYtbgoyrp8cCBgP2W8loSXfvjlX6WATaq1OdVXwPy4MHA/cDpcUj3Ac4bjEG7HEODomJuF4r6duypSqGCmC3pD2Zg3Bc58ptxfSWU6wPArMszwKrAhcATocCWH806N/DdEBgZAaN7rv7Zl2N8lsmOLtYiT3mRbmveeBEV1D9f8AvghaIT3fK/Og5uJrk2feLE3UgjeherxFeAAcRwwbERcZ8FLNrDk3ZfzAp8CVwRlOymsJxauyY4ETCmUDGFvPutUETvVwsFVfF/jnEmAU77R7zvvylD99nrndGngbcKunSfVJuCplcrdEEhY72KeVVR760pkjJAysWM+qQJ7SZwbribvN3YKJu6ci7t/jZvOLCb+y3wSEP5oRIzTjg0G9w0lxYzd82bZc9Lt/46IHXLcRTwfVRsGeu5cNxvUVjMvJ2GykOSoFd0L1LQaL2eeyILpVtXSKLvSclhJ9NH7i6vt6xymhLyVNTgM0+Um2mUWoOTadW+SQLczMJTtY6LulMA/wYCuiXHlIv1KiYH3Lv8wLnH7m/6OODc9WitglLjjDKtpCWeMF76NkCqI1XTo6wA7N5iQdYtYhnnYqBozJHgBwr1ZFSpnLp0T1WpnHIFUfJN63QdKrSDlNC8pxdfEbg5ku7p1CV5gzCpRA0urly1HWwr0R5MaE3M0T7cwaDSGzmW3mlMoXLsAmjZHmvRmfv5Rka7POg7V1J3tSA1dSnf3CQMWeKoJunTmNKGq0NvzGTIZ1XoEn5hmznTLZP8KvPeYT2TvIFVFboAXyaHFlOO8XFemZUluPLRHPOFeb44+Iif6d6PaHHuXDDK8lhP+XCBrrEbi3lcu+i0w5dfLAIR3WornB/5VZ/rxq8DtsmEXXM5ZX74Ny3ctAqtVzs42k0LyC+Xi3vp2ueAYxlX6JY1RKXhUwlfjTYGy+bMXY8ctj8nVeQdOKm74sEaQZ7lkgYwKbrWPWjG0wlS3KDHaNoXT/AF/HTnVyOtxA3AxpHAV0lzGFFqSY3ihwMMAHQ9eoQm8Euamyeafl0K8bYXN1qj0Q7rhKXWnaowBwHSkQTXXGORYgyNypKhsCqf81ber4SHAAaAUjT3MgVI7wIaNT/ObB0dGySbD98rDQQ4Fymg/NYcr14nKWsS87DoWQYM8sWXEontoldfWvc0HGCezkiz6XdnLaybLbRwfg6uwazJCS3+Umqv1k532spymp4x2NDytYNKNiZfqoy45ZklzG8n2L8GyEPdDmYC+rIIueVs16jds18jx2jSvs8kt2uQPZOTyme01L0O83nm7lSG/n60oWLoBs0N6n6FCqg7rEEl8rcMNbSiUzXZvE6lNg7ILWX+3LL555cj52nOshtsBbwDPAeoC9IHf3mV5zhVXutreew0prqox+3Tyb5CkujyqolWMU0nSNCbIhHiGoFu2sdgyBl8+EXIDWxF2F1Lc566QAMGrYXBQYJuLU+jpPqxcTW6ln4Y9fqFSAWswVy21C1F3jWZ/up005fGRxZ/LukvrqQvyT2rcCqwbt655Eqb9+2B1iNp6UcflDEx53nHlu1LC/hA+aDFvbzEib/W4nkvVWv9XOBOoaVNWQj5lTnAGk/UqpbBQRrLdJVUogZjgRvjr/Z8XN24Feh3BTy4uteUkuu3QQMB+3oP8Bdkpmj+c/gbmg9OPqsuK9UAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import math\n",
    "\n",
    "\n",
    "def create_data():\n",
    "    dataSets = [['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return dataSets, labels\n",
    "\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, label=None, featureIndex=None,feature_name=None, \n",
    "                 parentNode=None, leaf=False,entropy=0):\n",
    "        self.label = label\n",
    "        self.leaf = leaf  # 是否为叶结点\n",
    "        self.featureIndex = featureIndex\n",
    "        self.feature_name = feature_name\n",
    "        self.parentNode = parentNode\n",
    "        self.childNodeList = {}  # 存的是子结点的取值，如feature_name是身高，可能存的是高，矮\n",
    "        self.entropy=entropy\n",
    "        self.sampleLists=[]\n",
    "        self.prune_visited=False\n",
    "\n",
    "\n",
    "    def predict(self,node,Xtest):\n",
    "        if node.leaf:\n",
    "            return node.label\n",
    "        else:\n",
    "            currentFeatIndex=node.featureIndex\n",
    "            currentFeatVal=Xtest[currentFeatIndex]\n",
    "            return self.predict(node.childNodeList[currentFeatVal],Xtest)\n",
    "\n",
    "\n",
    "\n",
    "class dTree:\n",
    "    def __init__(self, epsilon=0.1,alpha=0.3):\n",
    "        self.epsilon = epsilon\n",
    "        self.myTree = None\n",
    "        self.completeDataSets=None\n",
    "        self.completeAttrs=None\n",
    "        self.leafNums=0\n",
    "        self.alpha=alpha  #用于剪枝\n",
    "\n",
    "\n",
    "    def treeGenerate(self,dataSets,labels):\n",
    "        self.myTree=Node(parentNode='root')\n",
    "        self.completeDataSets=dataSets.copy()\n",
    "        self.completeAttrs=labels.copy()\n",
    "        self.recursive(dataSets,labels,self.myTree)\n",
    "        print(\"generate tree success!\")\n",
    "\n",
    "\n",
    "    def recursive(self, dataSets, labels, node=Node()):\n",
    "        if self.isSameClass(dataSets):\n",
    "            node.label = dataSets[0][-1]\n",
    "            node.leaf = True\n",
    "            node.entropy=self.calcEntropy(dataSets)\n",
    "            node.sampleLists=dataSets\n",
    "            self.leafNums+=1\n",
    "            return\n",
    "        if len(labels[:-1]) == 0:\n",
    "            node.label = self.majorityClass(dataSets)\n",
    "            node.leaf = True\n",
    "            node.entropy = self.calcEntropy(dataSets)\n",
    "            node.sampleLists = dataSets\n",
    "            self.leafNums += 1\n",
    "            return\n",
    "\n",
    "        bestFeatIndex = self.chooseBestFeatureToSplit(dataSets, labels)\n",
    "        node.featureIndex = bestFeatIndex\n",
    "        node.feature_name = self.completeAttrs[bestFeatIndex]\n",
    "        node.entropy=self.calcEntropy(dataSets)\n",
    "        node.sampleLists=dataSets\n",
    "        featList = [data[bestFeatIndex] for data in self.completeDataSets]\n",
    "        uniqueFeatList = set(featList)\n",
    "        for feat in uniqueFeatList:\n",
    "            subNode = Node()\n",
    "            node.childNodeList[feat]=subNode\n",
    "            subNode.parentNode = node\n",
    "            subDataSets = self.splitData(dataSets, bestFeatIndex, feat)\n",
    "            if len(subDataSets) == 0:\n",
    "                subNode.label = self.majorityClass(dataSets)\n",
    "                subNode.leaf = True\n",
    "                self.leafNums += 1\n",
    "            else:\n",
    "                subLabels = labels.copy()\n",
    "                subLabels.remove(self.completeAttrs[bestFeatIndex])\n",
    "                self.recursive(subDataSets, subLabels, subNode)\n",
    "\n",
    "\n",
    "\n",
    "    def chooseBestFeatureToSplit(self, dataSets, labels):\n",
    "        baseEntropy = self.calcEntropy(dataSets)\n",
    "        m = len(dataSets)\n",
    "        bestInfoGain = -math.inf\n",
    "        bestFeatIndex = -1\n",
    "        for i in range(len(labels) - 1):  # 遍历每个属性\n",
    "            j=self.completeAttrs.index(labels[i])\n",
    "            featList = [data[j] for data in dataSets]\n",
    "            uniqueFeats = set(featList)  # 当前属性的取值\n",
    "            newEntropy = 0\n",
    "            for feat in uniqueFeats:  # 遍历当前属性的每个取值\n",
    "                subDataSets = self.splitData(dataSets, j, feat)\n",
    "                prob = len(subDataSets) / m\n",
    "                newEntropy += prob * self.calcEntropy(subDataSets)\n",
    "            currentInfoGain = baseEntropy - newEntropy\n",
    "            if currentInfoGain >= bestInfoGain:\n",
    "                bestInfoGain = currentInfoGain\n",
    "                bestFeatIndex = j\n",
    "        return bestFeatIndex\n",
    "\n",
    "\n",
    "    def splitData(self, dataSets, featIndex, featVals):\n",
    "        subDataSets = [data for data in dataSets if data[featIndex] == featVals]\n",
    "        return subDataSets\n",
    "\n",
    "\n",
    "    def calcEntropy(self, dataSets):\n",
    "        informationEnt = 0\n",
    "        m = len(dataSets)\n",
    "        classCountDict = self.classCount(dataSets)\n",
    "        for key in classCountDict.keys():\n",
    "            prob = classCountDict[key] / m\n",
    "            if prob == 0.0:\n",
    "                Ent = 0.0\n",
    "            else:\n",
    "                Ent = prob * math.log(prob,2)\n",
    "            informationEnt -= Ent\n",
    "        return informationEnt\n",
    "\n",
    "    def isSameClass(self, dataSets):\n",
    "        C = dataSets[0][-1]  # 第一个样本的类\n",
    "        for data in dataSets:\n",
    "            if C != data[-1]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "    def majorityClass(self, dataSets):\n",
    "        classCountDict = self.classCount(dataSets)\n",
    "        sortedClassCount = sorted(classCountDict.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        return sortedClassCount[0][0]\n",
    "\n",
    "\n",
    "    def classCount(self,dataSets):\n",
    "        classCountDict = {}\n",
    "        for data in dataSets:\n",
    "            if data[-1] not in classCountDict.keys():\n",
    "                classCountDict[data[-1]] = 1\n",
    "            else:\n",
    "                classCountDict[data[-1]] += 1\n",
    "        return classCountDict\n",
    "\n",
    "#后剪枝\n",
    "    def postPruning(self):\n",
    "        count=0\n",
    "        leafParentNode = self.getTheLeafParentNode(self.myTree)  #找到一个子结点全是叶结点的结点，并且该结点的prune_visited=False\n",
    "        while leafParentNode.parentNode!='root':  #找到根结点时停止\n",
    "            beforeLoss = self.compute_recursive(self.myTree)+self.alpha*self.leafNums\n",
    "            tmpLeafChildNode = leafParentNode.childNodeList.copy()  #将该结点的子结点保存起来\n",
    "            leafParentNode.childNodeList = {}  #先假设将子结点剪了\n",
    "            afterLoss = self.compute_recursive(self.myTree)+self.alpha*(self.leafNums-len(tmpLeafChildNode)+1)\n",
    "            if afterLoss > beforeLoss:  # 如果剪了后损失值更大了，就不剪\n",
    "                leafParentNode.childNodeList = tmpLeafChildNode\n",
    "            else:\n",
    "                leafParentNode.leaf=True\n",
    "                leafParentNode.label=self.majorityClass(leafParentNode.sampleLists)\n",
    "                self.leafNums=self.leafNums-len(tmpLeafChildNode)+1\n",
    "                print(\"prune node: %s\"%(leafParentNode.feature_name))\n",
    "                count+=1\n",
    "            leafParentNode = self.getTheLeafParentNode(self.myTree)  #寻找下一个子结点全是叶结点的结点\n",
    "        print(\"prune finished,cut %d node!\"%count)\n",
    "\n",
    "\n",
    "    def compute_recursive(self,tree):\n",
    "        loss=0\n",
    "        if tree.childNodeList:  #如果当前结点有子结点\n",
    "            for featVal,childNode in tree.childNodeList.items():\n",
    "                loss+=self.compute_recursive(childNode)\n",
    "        else:   #当前结点为叶结点\n",
    "            loss+=len(tree.sampleLists)*tree.entropy\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def getTheLeafParentNode(self,tree):\n",
    "        isAllChildNodeLeaf=True\n",
    "        if tree.childNodeList:  #如果当前结点有子结点，即不是叶结点\n",
    "            for key,childNode in tree.childNodeList.items():#遍历当前结点的所有子结点\n",
    "                if childNode.prune_visited:\n",
    "                    continue\n",
    "                if childNode.childNodeList:  #当前迭代下的子结点如果还有子结点，即不是叶节点的话\n",
    "                    isAllChildNodeLeaf=False\n",
    "                    return self.getTheLeafParentNode(childNode)  #递归地对非叶结点调用此方法\n",
    "            if isAllChildNodeLeaf and not tree.prune_visited:   #如果当前结点所有子结点都是叶结点\n",
    "                tree.prune_visited=True\n",
    "                return tree\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self,Xtest):\n",
    "        return self.myTree.predict(self.myTree,Xtest)\n",
    "\n",
    "\n",
    "    def score(self,testDatas):\n",
    "        #testDatas需要是至少有两个样本的list\n",
    "        y=[data[-1] for data in testDatas]\n",
    "        predictY=[]\n",
    "        for Xtest in testDatas:\n",
    "            predictY.append(self.predict(Xtest[:-1]))\n",
    "        m=len(y)\n",
    "        count=0\n",
    "        for i in range(m):\n",
    "            if y[i]==predictY[i]:\n",
    "                count+=1\n",
    "        accuracy=float(count/m)*100\n",
    "        print(y)\n",
    "        print(predictY)\n",
    "        print(\"accuracy is \"+str(accuracy)+\"%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate tree success!\n",
      "['否', '否', '是', '是', '否', '否', '否', '是', '是', '是', '是', '是', '是', '是', '否']\n",
      "['否', '否', '是', '是', '否', '否', '否', '是', '是', '是', '是', '是', '是', '是', '否']\n",
      "accuracy is 100.0%\n",
      "prune finished,cut 0 node!\n"
     ]
    }
   ],
   "source": [
    "firstDataSets,firstLabels=create_data()\n",
    "firstMyTree=dTree()\n",
    "firstMyTree.treeGenerate(firstDataSets,firstLabels)\n",
    "firstMyTree.score(firstDataSets)\n",
    "firstMyTree.postPruning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一组数据生成的决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./ID3_tree_pics/Figure_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate tree success!\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "accuracy is 100.0%\n",
      "prune finished,cut 0 node!\n"
     ]
    }
   ],
   "source": [
    "secondDataSets=[\n",
    "['青绿','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['乌黑','蜷缩','沉闷','清晰','凹陷','硬滑',1],\n",
    "['乌黑','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['青绿','蜷缩','沉闷','清晰','凹陷','硬滑',1],\n",
    "['浅白','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['青绿','稍蜷','浊响','清晰','稍凹','软粘',1],\n",
    "['乌黑','稍蜷','浊响','稍糊','稍凹','软粘',1],\n",
    "['乌黑','稍蜷','浊响','清晰','稍凹','硬滑',1],\n",
    "['乌黑','稍蜷','沉闷','稍糊','稍凹','硬滑',0],\n",
    "['青绿','硬挺','清脆','清晰','平坦','软粘',0],\n",
    "['浅白','硬挺','清脆','模糊','平坦','硬滑',0],\n",
    "['浅白','蜷缩','浊响','模糊','平坦','软粘',0],\n",
    "['青绿','稍蜷','浊响','稍糊','凹陷','硬滑',0],\n",
    "['浅白','稍蜷','沉闷','稍糊','凹陷','硬滑',0],\n",
    "['乌黑','稍蜷','浊响','清晰','稍凹','软粘',0],\n",
    "['浅白','蜷缩','浊响','模糊','平坦','硬滑',0],\n",
    "['青绿','蜷缩','沉闷','稍糊','稍凹','硬滑',0]]\n",
    "\n",
    "secondLabels=[u'色泽', u'根蒂', u'敲声', u'纹理', u'脐部', u'触感',u'类别']\n",
    "\n",
    "\n",
    "secondMyTree=dTree()\n",
    "secondMyTree.treeGenerate(secondDataSets,secondLabels)\n",
    "secondMyTree.score(secondDataSets)\n",
    "secondMyTree.postPruning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二组数据生成的决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./ID3_tree_pics/Figure_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate tree success!\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "accuracy is 100.0%\n",
      "prune finished,cut 0 node!\n"
     ]
    }
   ],
   "source": [
    "thirdDataSets=[\n",
    "['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 1],\n",
    "['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', 1],\n",
    "['乌黑', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 1],\n",
    "['青绿', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 1],\n",
    "['乌黑', '稍蜷', '浊响', '稍糊', '稍凹', '软粘', 1],\n",
    "['青绿', '硬挺', '清脆', '清晰', '平坦', '软粘', 0],\n",
    "['浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', 0],\n",
    "['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 0],\n",
    "['浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', 0],\n",
    "['青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑', 0]]\n",
    "\n",
    "thirdLabels=[u'色泽', u'根蒂', u'敲声', u'纹理', u'脐部', u'触感',u'类别']\n",
    "\n",
    "thirdTestDataSets=[\n",
    "['青绿','蜷缩','沉闷','清晰','凹陷','硬滑',1],\n",
    "['浅白','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['乌黑','稍蜷','浊响','清晰','稍凹','硬滑',1],\n",
    "['乌黑','稍蜷','沉闷','稍糊','稍凹','硬滑',0],\n",
    "['浅白','硬挺','清脆','模糊','平坦','硬滑',0],\n",
    "['浅白','蜷缩','浊响','模糊','平坦','软粘',0],\n",
    "['青绿','稍蜷','浊响','稍糊','凹陷','硬滑',0]]\n",
    "\n",
    "thirdMyTree=dTree()\n",
    "thirdMyTree.treeGenerate(thirdDataSets,thirdLabels)\n",
    "thirdMyTree.score(thirdDataSets)\n",
    "thirdMyTree.postPruning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三组数据生成的决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./ID3_tree_pics/Figure_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 0, 0]\n",
      "accuracy is 85.71428571428571%\n"
     ]
    }
   ],
   "source": [
    "thirdMyTree.score(thirdTestDataSets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为何以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的特征的问题：\n",
    "可以这样想假如这个特征取值特别多，每个样本就有一个取值，如果选择这个特征，那么每个分支都只有一条实例，也就是每个分支都属于同一个类，这个分支的熵就是0，这个特征的条件熵也就是0，那么基于这个特征的信息增益g(D,A)=H(D)-0=H(D)，就会是最大的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树的剪枝\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树的剪枝分为预剪枝和后剪枝，预剪枝则是判断划分当前结点后验证集精确度是否提高（西瓜书），或者是损失函数值是否减少（统计学习方法），若是，则划分。而后剪枝是先生成好决策树，递归地试试删除结点能否提高验证集精确度或者减少损失函数值，若是，则剪枝。本模型只实现了postpruning（后剪枝）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对于连续属性的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定样本集D和连续属性a，假定a在D上出现了n个不同的取值，将这些值从小到大进行排序，记为{a1,a2,...,an}，基于划分点t可将D分为子集Dt-,Dt+，Dt-包含a上取值不大于t的样本，而Dt+则包含那些在属性a上取值大于t的样本Gain(D,a)=max Gain(D,a,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet,contiualLabels):  #dataSet只包含连续属性\n",
    "    baseEntropy=self.calcEntropy(labels)\n",
    "    bestInfoGain=-math.inf\n",
    "    bestT=-1\n",
    "    for k in range(len(contiualLabels)):\n",
    "        featList = [float(example[k]) for example in dataSets]\n",
    "        sortedFeatList=featList.copy()\n",
    "        sortedFeatList.sort()\n",
    "        #求Ta\n",
    "        for j in range(len(featList)-1):\n",
    "            InfoGain = 0\n",
    "            T=0.5*(sortedFeatList[j]+sortedFeatList[j+1])\n",
    "            posDataSets,negDataSets=splitDataByT(dataSets,k,T)\n",
    "            InfoGain=InfoGain+((len(posDataSets)/len(dataSet))*calcEntropy(posDataSets))+((len(negDataSets)/len(dataSet))*calcEntropy(negDataSets))\n",
    "            Gain=baseEntropy-InfoGain\n",
    "            if Gain > bestInfoGain:\n",
    "                bestInfoGain = Gain\n",
    "                bestFeature = k\n",
    "                bestT=T\n",
    "    return bestFeature,bestT\n",
    "\n",
    "\n",
    "def splitDataByT(dataSets,featIndex,T):\n",
    "    posDataSets=[data for data in dataSets if data[featIndex]>T]\n",
    "    negDataSets=[data for data in dataSets if data[featIndex]<=T]\n",
    "    return posDataSets,negDataSets\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "连续属性的处理见上面代码\n",
    "需注意的是，与离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性。\n",
    "例如在父结点上使用了“密度<=0.381”不会禁止在子结点上使用“密度<=0.294”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
