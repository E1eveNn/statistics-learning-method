{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：图可能有点不一样，因为图是基于if currentInfoGainRatio > bestInfoGain:生成的决策树画的，而后来改了下代码，改成了if currentInfoGainRatio >= bestInfoGain:，生成的树可能会不一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4.5几乎和ID3算法一样，只是ID3基于信息增益来划分，每次选择特征时选择信息增益大的来划分，而C4.5选择信息增益比大的来划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征A对训练数据集D的信息增益比定义为其信息增益g(D,A)与训练数据集D关于特征A的值的熵HA(D)之比"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./C4.5_tree_pics/formula1.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中HA(D)定义如下，n是特征A取值的个数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./C4.5_tree_pics/formula2.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比起ID3的代码变化的地方："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加了这句\n",
    "<img src='./C4.5_tree_pics/formula3.png'></img>\n",
    "用于计算HA(D),其中prob=|Di|/|D|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和这句\n",
    "<img src='./C4.5_tree_pics/formula4.png'></img>\n",
    "若当前数据集D中关于当前特征A只有1个取值，即D上特征A的取值全相同，此时prob=1，所以log（prob）=0，所以HfeatEntropy会等于0，在下面的除法中分母为0会出现错误。\n",
    "不过当前数据集D中关于当前特征A只有1个取值时g(D,A)=0，所以HfeatEntropy=0时一定有currentInfoGain=0，反之亦然，所以只需要判断currentInfoGain是否为0即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import math\n",
    "\n",
    "\n",
    "def create_data():\n",
    "    dataSets = [['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return dataSets, labels\n",
    "\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, label=None, featureIndex=None ,feature_name=None, \n",
    "                 parentNode=None, leaf=False,entropy=0):\n",
    "        \n",
    "        self.label = label\n",
    "        self.leaf = leaf  # 是否为叶结点\n",
    "        self.featureIndex = featureIndex\n",
    "        self.feature_name = feature_name\n",
    "        self.parentNode = parentNode\n",
    "        self.childNodeList = {}  # 存的是子结点的取值，如feature_name是身高，可能存的是高，矮\n",
    "        self.entropy=entropy\n",
    "        self.sampleLists=[]\n",
    "        self.prune_visited=False \n",
    "\n",
    "    def predict(self,node,Xtest):\n",
    "        if node.leaf:\n",
    "            return node.label\n",
    "        else:\n",
    "            currentFeatIndex=node.featureIndex\n",
    "            currentFeatVal=Xtest[currentFeatIndex]\n",
    "            return self.predict(node.childNodeList[currentFeatVal],Xtest)\n",
    "\n",
    "\n",
    "\n",
    "class dTree:\n",
    "    def __init__(self, epsilon=0.1,alpha=0.3):\n",
    "        self.epsilon = epsilon\n",
    "        self.myTree = None\n",
    "        self.completeDataSets=None\n",
    "        self.completeAttrs=None\n",
    "        self.leafNums=0\n",
    "        self.alpha=alpha  #用于剪枝\n",
    "\n",
    "\n",
    "    def treeGenerate(self,dataSets,labels):\n",
    "        self.myTree=Node(parentNode='root')\n",
    "        self.completeDataSets=dataSets.copy()\n",
    "        self.completeAttrs=labels.copy()\n",
    "        self.recursive(dataSets,labels,self.myTree)\n",
    "        print(\"generate tree success!\")\n",
    "\n",
    "\n",
    "    def recursive(self, dataSets, labels, node=Node()):\n",
    "        if self.isSameClass(dataSets):\n",
    "            node.label = dataSets[0][-1]\n",
    "            node.leaf = True\n",
    "            node.entropy=self.calcEntropy(dataSets)\n",
    "            node.sampleLists=dataSets\n",
    "            self.leafNums+=1\n",
    "            return\n",
    "        if len(labels[:-1]) == 0:\n",
    "            node.label = self.majorityClass(dataSets)\n",
    "            node.leaf = True\n",
    "            node.entropy=self.calcEntropy(dataSets)\n",
    "            node.sampleLists=dataSets\n",
    "            self.leafNums+=1\n",
    "            return\n",
    "\n",
    "        bestFeatIndex = self.chooseBestFeatureToSplit(dataSets, labels)\n",
    "        node.featureIndex = bestFeatIndex\n",
    "        node.feature_name = self.completeAttrs[bestFeatIndex]\n",
    "        node.entropy=self.calcEntropy(dataSets)\n",
    "        node.sampleLists=dataSets\n",
    "        featList = [data[bestFeatIndex] for data in self.completeDataSets]\n",
    "        uniqueFeatList = set(featList)\n",
    "        for feat in uniqueFeatList:\n",
    "            subNode = Node()\n",
    "            node.childNodeList[feat]=subNode\n",
    "            subNode.parentNode = node\n",
    "            subDataSets = self.splitData(dataSets, bestFeatIndex, feat)\n",
    "            if len(subDataSets) == 0:\n",
    "                subNode.label = self.majorityClass(dataSets)\n",
    "                subNode.leaf = True\n",
    "                self.leafNums += 1\n",
    "            else:\n",
    "                subLabels = labels.copy()\n",
    "                subLabels.remove(self.completeAttrs[bestFeatIndex])\n",
    "                self.recursive(subDataSets, subLabels, subNode)\n",
    "\n",
    "\n",
    "\n",
    "    def chooseBestFeatureToSplit(self, dataSets, labels):\n",
    "        baseEntropy = self.calcEntropy(dataSets)\n",
    "        m = len(dataSets)\n",
    "        bestInfoGain = -math.inf\n",
    "        bestFeatIndex = -1\n",
    "        for i in range(len(labels) - 1):  # 遍历每个属性\n",
    "            j=self.completeAttrs.index(labels[i])\n",
    "            featList = [data[j] for data in dataSets]\n",
    "            uniqueFeats = set(featList)  # 当前属性的取值\n",
    "            newEntropy = 0\n",
    "            HfeatEntropy = 0\n",
    "            for feat in uniqueFeats:  # 遍历当前属性的每个取值\n",
    "                subDataSets = self.splitData(dataSets, j, feat)\n",
    "                prob = len(subDataSets) / m\n",
    "                newEntropy += prob * self.calcEntropy(subDataSets)\n",
    "                HfeatEntropy -= (prob * math.log(prob, 2))\n",
    "            currentInfoGain = baseEntropy - newEntropy\n",
    "            if currentInfoGain==0:\n",
    "                currentInfoGainRatio=0\n",
    "            else:\n",
    "                currentInfoGainRatio=currentInfoGain/HfeatEntropy\n",
    "            if currentInfoGainRatio >= bestInfoGain:\n",
    "                bestInfoGain = currentInfoGainRatio\n",
    "                bestFeatIndex = j\n",
    "        return bestFeatIndex\n",
    "\n",
    "\n",
    "    def splitData(self, dataSets, featIndex, featVals):\n",
    "        subDataSets = [data for data in dataSets if data[featIndex] == featVals]\n",
    "        return subDataSets\n",
    "\n",
    "\n",
    "    def calcEntropy(self, dataSets):\n",
    "        informationEnt = 0\n",
    "        m = len(dataSets)\n",
    "        classCountDict = self.classCount(dataSets)\n",
    "        for key in classCountDict.keys():\n",
    "            prob = classCountDict[key] / m\n",
    "            if prob == 0.0:\n",
    "                Ent = 0.0\n",
    "            else:\n",
    "                Ent = prob * math.log(prob,2)\n",
    "            informationEnt -= Ent\n",
    "        return informationEnt\n",
    "\n",
    "    def isSameClass(self, dataSets):\n",
    "        C = dataSets[0][-1]  # 第一个样本的类\n",
    "        for data in dataSets:\n",
    "            if C != data[-1]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "    def isSameValue(self, dataSets, labels):\n",
    "        #！！！不能用把dataSets上所有的取值放到一个set里，然后来简单判断下set的长度是否等于labels的长度，以下为例子\n",
    "        # case 1：\n",
    "        #      dataSets=[['绿','高',1],['绿','高',1]]\n",
    "        #      labels=['颜色','高度','类别']\n",
    "        #      此时dataSets的set为（'绿','高',1）,set的长度与labels的长度一样，可以判定为dataSets所有样本取值相同，但还有其他情况\n",
    "        # case 2：\n",
    "        #      dataSets=[[1,'高',1],[1,'高',1]]\n",
    "        #      labels=['长度','高度','类别']\n",
    "        #      此时dataSets的set为（'高',1），set的长度就不与labels的长度一样了，但dataSets上所有样本取值仍然是相同的\n",
    "        flag=True\n",
    "        for i in range(len(labels)-1):\n",
    "            value = []\n",
    "            for data in dataSets:\n",
    "                value.append(data[i])\n",
    "            if len(set(value))!=1:\n",
    "                flag=False\n",
    "        return flag\n",
    "\n",
    "\n",
    "    def majorityClass(self, dataSets):\n",
    "        classCountDict = self.classCount(dataSets)\n",
    "        sortedClassCount = sorted(classCountDict.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        return sortedClassCount[0][0]\n",
    "\n",
    "\n",
    "    def classCount(self,dataSets):\n",
    "        classCountDict = {}\n",
    "        for data in dataSets:\n",
    "            if data[-1] not in classCountDict.keys():\n",
    "                classCountDict[data[-1]] = 1\n",
    "            else:\n",
    "                classCountDict[data[-1]] += 1\n",
    "        return classCountDict\n",
    "\n",
    "\n",
    "    def predict(self,Xtest):\n",
    "        return self.myTree.predict(self.myTree,Xtest)\n",
    "\n",
    "\n",
    "    def score(self,testDatas):\n",
    "        #testDatas需要是至少有两个样本的list\n",
    "        y=[data[-1] for data in testDatas]\n",
    "        predictY=[]\n",
    "        for Xtest in testDatas:\n",
    "            predictY.append(self.predict(Xtest[:-1]))\n",
    "        m=len(y)\n",
    "        count=0\n",
    "        for i in range(m):\n",
    "            if y[i]==predictY[i]:\n",
    "                count+=1\n",
    "        accuracy=float(count/m)*100\n",
    "        print(y)\n",
    "        print(predictY)\n",
    "        print(\"accuracy is \"+str(accuracy)+\"%\")\n",
    "\n",
    "        \n",
    "#后剪枝\n",
    "    def postPruning(self):\n",
    "        count=0\n",
    "        leafParentNode = self.getTheLeafParentNode(self.myTree)  #找到一个子结点全是叶结点的结点，并且该结点的prune_visited=False\n",
    "        while leafParentNode.parentNode!='root':  #找到根结点时停止\n",
    "            beforeLoss = self.compute_recursive(self.myTree)+self.alpha*self.leafNums\n",
    "            tmpLeafChildNode = leafParentNode.childNodeList.copy()  #将该结点的子结点保存起来\n",
    "            leafParentNode.childNodeList = {}  #先假设将子结点剪了\n",
    "            afterLoss = self.compute_recursive(self.myTree)+self.alpha*(self.leafNums-len(tmpLeafChildNode)+1)\n",
    "            if afterLoss > beforeLoss:  # 如果剪了后损失值更大了，就不剪\n",
    "                leafParentNode.childNodeList = tmpLeafChildNode\n",
    "            else:\n",
    "                leafParentNode.leaf=True\n",
    "                leafParentNode.label=self.majorityClass(leafParentNode.sampleLists)\n",
    "                self.leafNums=self.leafNums-len(tmpLeafChildNode)+1\n",
    "                print(\"prune node: %s\"%(leafParentNode.feature_name))\n",
    "                count+=1\n",
    "            leafParentNode = self.getTheLeafParentNode(self.myTree)  #寻找下一个子结点全是叶结点的结点\n",
    "        print(\"prune finished,cut %d node!\"%count)\n",
    "\n",
    "\n",
    "    def compute_recursive(self,tree):\n",
    "        loss=0\n",
    "        if tree.childNodeList:  #如果当前结点有子结点\n",
    "            for featVal,childNode in tree.childNodeList.items():\n",
    "                loss+=self.compute_recursive(childNode)\n",
    "        else:   #当前结点为叶结点\n",
    "            loss+=len(tree.sampleLists)*tree.entropy\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def getTheLeafParentNode(self,tree):\n",
    "        isAllChildNodeLeaf=True\n",
    "        if tree.childNodeList:  #如果当前结点有子结点，即不是叶结点\n",
    "            for key,childNode in tree.childNodeList.items():#遍历当前结点的所有子结点\n",
    "                if childNode.prune_visited:\n",
    "                    continue\n",
    "                if childNode.childNodeList:  #当前迭代下的子结点如果还有子结点，即不是叶节点的话\n",
    "                    isAllChildNodeLeaf=False\n",
    "                    return self.getTheLeafParentNode(childNode)  #递归地对非叶结点调用此方法\n",
    "            if isAllChildNodeLeaf and not tree.prune_visited:   #如果当前结点所有子结点都是叶结点\n",
    "                tree.prune_visited=True\n",
    "                return tree\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate tree success!\n",
      "['否', '否', '是', '是', '否', '否', '否', '是', '是', '是', '是', '是', '是', '是', '否']\n",
      "['否', '否', '是', '是', '否', '否', '否', '是', '是', '是', '是', '是', '是', '是', '否']\n",
      "accuracy is 100.0%\n",
      "prune finished,cut 0 node!\n"
     ]
    }
   ],
   "source": [
    "firstDataSets,firstLabels=create_data()\n",
    "firstMyTree=dTree()\n",
    "firstMyTree.treeGenerate(firstDataSets,firstLabels)\n",
    "firstMyTree.score(firstDataSets)\n",
    "firstMyTree.postPruning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一组数据生成的决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./C4.5_tree_pics/Figure_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate tree success!\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "accuracy is 100.0%\n",
      "prune finished,cut 0 node!\n"
     ]
    }
   ],
   "source": [
    "secondDataSets=[\n",
    "['青绿','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['乌黑','蜷缩','沉闷','清晰','凹陷','硬滑',1],\n",
    "['乌黑','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['青绿','蜷缩','沉闷','清晰','凹陷','硬滑',1],\n",
    "['浅白','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['青绿','稍蜷','浊响','清晰','稍凹','软粘',1],\n",
    "['乌黑','稍蜷','浊响','稍糊','稍凹','软粘',1],\n",
    "['乌黑','稍蜷','浊响','清晰','稍凹','硬滑',1],\n",
    "['乌黑','稍蜷','沉闷','稍糊','稍凹','硬滑',0],\n",
    "['青绿','硬挺','清脆','清晰','平坦','软粘',0],\n",
    "['浅白','硬挺','清脆','模糊','平坦','硬滑',0],\n",
    "['浅白','蜷缩','浊响','模糊','平坦','软粘',0],\n",
    "['青绿','稍蜷','浊响','稍糊','凹陷','硬滑',0],\n",
    "['浅白','稍蜷','沉闷','稍糊','凹陷','硬滑',0],\n",
    "['乌黑','稍蜷','浊响','清晰','稍凹','软粘',0],\n",
    "['浅白','蜷缩','浊响','模糊','平坦','硬滑',0],\n",
    "['青绿','蜷缩','沉闷','稍糊','稍凹','硬滑',0]]\n",
    "\n",
    "secondLabels=[u'色泽', u'根蒂', u'敲声', u'纹理', u'脐部', u'触感',u'类别']\n",
    "\n",
    "\n",
    "secondMyTree=dTree()\n",
    "secondMyTree.treeGenerate(secondDataSets,secondLabels)\n",
    "secondMyTree.score(secondDataSets)\n",
    "secondMyTree.postPruning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二组数据生成的决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./C4.5_tree_pics/Figure_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate tree success!\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "accuracy is 100.0%\n",
      "prune finished,cut 0 node!\n"
     ]
    }
   ],
   "source": [
    "thirdDataSets=[\n",
    "['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 1],\n",
    "['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', 1],\n",
    "['乌黑', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 1],\n",
    "['青绿', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 1],\n",
    "['乌黑', '稍蜷', '浊响', '稍糊', '稍凹', '软粘', 1],\n",
    "['青绿', '硬挺', '清脆', '清晰', '平坦', '软粘', 0],\n",
    "['浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', 0],\n",
    "['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 0],\n",
    "['浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', 0],\n",
    "['青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑', 0]]\n",
    "\n",
    "thirdLabels=[u'色泽', u'根蒂', u'敲声', u'纹理', u'脐部', u'触感',u'类别']\n",
    "\n",
    "thirdTestDataSets=[\n",
    "['青绿','蜷缩','沉闷','清晰','凹陷','硬滑',1],\n",
    "['浅白','蜷缩','浊响','清晰','凹陷','硬滑',1],\n",
    "['乌黑','稍蜷','浊响','清晰','稍凹','硬滑',1],\n",
    "['乌黑','稍蜷','沉闷','稍糊','稍凹','硬滑',0],\n",
    "['浅白','硬挺','清脆','模糊','平坦','硬滑',0],\n",
    "['浅白','蜷缩','浊响','模糊','平坦','软粘',0],\n",
    "['青绿','稍蜷','浊响','稍糊','凹陷','硬滑',0]]\n",
    "\n",
    "thirdMyTree=dTree()\n",
    "thirdMyTree.treeGenerate(thirdDataSets,thirdLabels)\n",
    "thirdMyTree.score(thirdDataSets)\n",
    "thirdMyTree.postPruning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三组数据生成的决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./C4.5_tree_pics/Figure_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 0, 0]\n",
      "accuracy is 85.71428571428571%\n"
     ]
    }
   ],
   "source": [
    "thirdMyTree.score(thirdTestDataSets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
